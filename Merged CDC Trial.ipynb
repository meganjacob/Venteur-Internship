{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FINT_Y_P</th>\n",
       "      <th>FINT_M_P</th>\n",
       "      <th>FMX</th>\n",
       "      <th>RECTYPE</th>\n",
       "      <th>SRVY_YR</th>\n",
       "      <th>HHX</th>\n",
       "      <th>FM_SIZE</th>\n",
       "      <th>FM_STRCP</th>\n",
       "      <th>FM_TYPE</th>\n",
       "      <th>FM_STRP</th>\n",
       "      <th>...</th>\n",
       "      <th>COVCONF</th>\n",
       "      <th>FHICOST</th>\n",
       "      <th>FMEDBILL</th>\n",
       "      <th>FMEDBPAY</th>\n",
       "      <th>FMEDBNOP</th>\n",
       "      <th>FSAF</th>\n",
       "      <th>FHICOVCT</th>\n",
       "      <th>FHICOVYN</th>\n",
       "      <th>FPRCOOH</th>\n",
       "      <th>FHIEBCCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FINT_Y_P  FINT_M_P  FMX  RECTYPE  SRVY_YR  HHX  FM_SIZE  FM_STRCP  FM_TYPE  \\\n",
       "0      2018         1    1       60     2018    1        1        11        1   \n",
       "1      2018         1    1       60     2018    4        3        41        4   \n",
       "2      2018         2    1       60     2018    6        4        41        4   \n",
       "3      2018         3    1       60     2018    8        3        41        4   \n",
       "4      2018         2    1       60     2018    9        1        11        1   \n",
       "\n",
       "   FM_STRP  ...  COVCONF  FHICOST  FMEDBILL  FMEDBPAY  FMEDBNOP  FSAF  \\\n",
       "0       11  ...      NaN        1         2         2       NaN     2   \n",
       "1       41  ...      4.0        2         1         1       1.0     2   \n",
       "2       41  ...      1.0        2         2         2       NaN     1   \n",
       "3       41  ...      3.0        3         2         1       NaN     2   \n",
       "4       11  ...      NaN        2         1         1       1.0     2   \n",
       "\n",
       "   FHICOVCT  FHICOVYN  FPRCOOH  FHIEBCCT  \n",
       "0         1         1      NaN       NaN  \n",
       "1         3         1      2.0       3.0  \n",
       "2         4         1      2.0       4.0  \n",
       "3         3         1      2.0       3.0  \n",
       "4         1         1      2.0       0.0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family = pd.read_csv('Data/familyxx.csv')\n",
    "family.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPX</th>\n",
       "      <th>AGE_CHG</th>\n",
       "      <th>INTV_QRT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>NOWAF</th>\n",
       "      <th>FSPOUS2</th>\n",
       "      <th>COHAB1</th>\n",
       "      <th>COHAB2</th>\n",
       "      <th>FCOHAB3</th>\n",
       "      <th>ASTATFLG</th>\n",
       "      <th>...</th>\n",
       "      <th>EDUC1</th>\n",
       "      <th>ERNYR_P</th>\n",
       "      <th>ARMFTM7P</th>\n",
       "      <th>ARMFTM1P</th>\n",
       "      <th>ARMFTM2P</th>\n",
       "      <th>ARMFTM3P</th>\n",
       "      <th>ARMFTM4P</th>\n",
       "      <th>ARMFTM5P</th>\n",
       "      <th>ARMFTM6P</th>\n",
       "      <th>ENGLANG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FPX  AGE_CHG  INTV_QRT  SEX  NOWAF  FSPOUS2  COHAB1  COHAB2  FCOHAB3  \\\n",
       "0    1      NaN         1    2    NaN      NaN     NaN     NaN      NaN   \n",
       "1    1      NaN         1    2    2.0      2.0     NaN     NaN      NaN   \n",
       "2    2      NaN         1    1    2.0      1.0     NaN     NaN      NaN   \n",
       "3    3      NaN         1    1    NaN      NaN     NaN     NaN      NaN   \n",
       "4    1      NaN         1    1    2.0      2.0     NaN     NaN      NaN   \n",
       "\n",
       "   ASTATFLG  ...  EDUC1  ERNYR_P  ARMFTM7P  ARMFTM1P  ARMFTM2P  ARMFTM3P  \\\n",
       "0       1.0  ...      9      NaN       NaN       NaN       NaN       NaN   \n",
       "1       2.0  ...     14      NaN       NaN       NaN       NaN       NaN   \n",
       "2       0.0  ...     15      7.0       NaN       NaN       NaN       NaN   \n",
       "3       NaN  ...     10      NaN       NaN       NaN       NaN       NaN   \n",
       "4       1.0  ...     21     11.0       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   ARMFTM4P  ARMFTM5P  ARMFTM6P  ENGLANG  \n",
       "0       NaN       NaN       NaN      1.0  \n",
       "1       NaN       NaN       NaN      1.0  \n",
       "2       NaN       NaN       NaN      1.0  \n",
       "3       NaN       NaN       NaN      1.0  \n",
       "4       NaN       NaN       NaN      1.0  \n",
       "\n",
       "[5 rows x 602 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = pd.read_csv('Data/personsx.csv')\n",
    "person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "household = pd.read_csv('Data/househld.csv')\n",
    "# household.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('Data/samadult.csv')\n",
    "# adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = pd.read_csv('Data/samchild.csv')\n",
    "# child.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having issues with merging --> possibly a file size issue, only working with smaller portions of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.1 GiB for an array with shape (2156872938,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-195cde75b478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# merge family and person\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# merged = pd.merge(person,family,on='FMX',how='outer')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmerged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'FMX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   7944\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7946\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m   7947\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7948\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     )\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         llabels, rlabels = _items_overlap_with_suffix(\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_join_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;34m\"\"\" return the join indexers \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m         return _get_join_indexers(\n\u001b[0m\u001b[0;32m    863\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     }[how]\n\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mjoin_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\join.pyx\u001b[0m in \u001b[0;36mpandas._libs.join.left_outer_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.1 GiB for an array with shape (2156872938,) and data type int64"
     ]
    }
   ],
   "source": [
    "# merge family and person\n",
    "# merged = pd.merge(person,family,on='FMX',how='outer')\n",
    "merged = person.merge(family, on = 'FMX', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income related factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = merged[['WRKHRS2', 'WRKFTALL', 'WRKLYR1', 'WRKMYR', 'ERNYR_P', 'HIEMPOF', 'PSAL', 'PSEINC', 'PHCDN2WP', 'P10DVYR', 'PHCPN2WP', 'PHCDV2W', 'PHCHM2W']]\n",
    "# healthcare visit related --> 'PHCDN2WP', 'P10DVYR', 'PHCPN2WP', 'PHCDV2W', 'PHCHM2W'\n",
    "# income realted --> 'WRKHRS2', 'WRKFTALL', 'WRKLYR1', 'WRKMYR', 'ERNYR_P', 'HIEMPOF', 'PSAL', 'PSEINC'\n",
    "\n",
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(income.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns have null values --> how should i deal with null values?\n",
    "for i in income.columns:\n",
    "    if(income[i].isnull().values.any()):\n",
    "        print(i + '  True  ' + str(income[i].isnull().sum()))\n",
    "    else:\n",
    "        print(i + '  False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values with mean --> is this a good approach or should I take a different one?\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "for i in income.columns:\n",
    "    income[i] = income[i].fillna(round(income[i].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values 7, 8, 9 (refused, not ascertained, don't know)\n",
    "income = income[income['PHCHM2W'] < 7]\n",
    "income.PHCHM2W.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = income[['WRKHRS2', 'WRKFTALL', 'WRKLYR1', 'WRKMYR', 'ERNYR_P', 'HIEMPOF', 'PSAL', 'PSEINC']]\n",
    "y = income['PHCHM2W']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "sc = ss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_test = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "cm_train = confusion_matrix(y_pred_train, y_train)\n",
    "\n",
    "print()\n",
    "print('Accuracy for training set for Random Forest = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))\n",
    "print('Accuracy for test set for Random Forest = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by highest feature importance\n",
    "sorted_idx = classifier.feature_importances_.argsort()\n",
    "plt.barh(X.columns[sorted_idx], classifier.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "classifier.feature_importances_[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = merged[['PLIMANY', 'LAHCC6', 'LAHCC7A', 'LAHCC8', 'LAHCC10', 'LAHCC11', 'PHCDN2WP', 'P10DVYR', 'PHCPN2WP', 'PHCDV2W', 'PHCHM2W']]\n",
    "# factors --> 'PLIMANY', 'LAHCC6', 'LAHCC7A', 'LAHCC8', 'LAHCC10', 'LAHCC11'\n",
    "# healthcare visit --> 'PHCDN2WP', 'P10DVYR', 'PHCPN2WP', 'PHCDV2W', 'PHCHM2W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_vars = merged[['LCCHRC1', 'LCCHRC2', 'LCCHRC3', 'LCCHRC4', 'LCCHRC5', 'LCCHRC6', 'LCCHRC8', 'LCCHRC9', 'LCCHRC10', 'LCCHRC11', 'LCCHRC12', 'LCCHRC13', 'LCCHRC90', 'LCCHRC91', 'PHCDN2WP', 'P10DVYR', 'PHCPN2WP', 'PHCDV2W', 'PHCHM2W']]\n",
    "# healthcare visit --> 'PHCDN2WP', 'P10DVYR', 'PHCPN2WP', 'PHCDV2W', 'PHCHM2W'\n",
    "# status variables --> 'LCCHRC1', 'LCCHRC2', 'LCCHRC3', 'LCCHRC4', 'LCCHRC5', 'LCCHRC6', 'LCCHRC8', 'LCCHRC9', 'LCCHRC10', 'LCCHRC11', 'LCCHRC12', 'LCCHRC13', 'LCCHRC90', 'LCCHRC91'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(factors.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(status_vars.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['LCCHRC1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['LCCHRC1']:\n",
    "    if(merged[i].isnull().values.any()):\n",
    "        print(i + '  True  ' + str(merged[i].isnull().sum()))\n",
    "    else:\n",
    "        print(i + '  False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['LCCHRC1']:\n",
    "    if(person[i].isnull().values.any()):\n",
    "        print(i + '  True  ' + str(person[i].isnull().sum()))\n",
    "    else:\n",
    "        print(i + '  False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family of 4 percent insured\n",
    "X = family_4['FM_SIZE']\n",
    "y = family_4['percent_insured']\n",
    "y.value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
